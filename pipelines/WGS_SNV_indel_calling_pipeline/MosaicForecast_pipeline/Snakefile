configfile: "snake_conf.yaml"

localrules: all, generate_avinput, generate_bed, \
            summarize_results, split_avinput, gather_tumor_ci_results, \
            gather_homopolyer_results, _gather_normal_ci_results, \

#recommand smaller for strelka
SPLITS = ["%02d" % x for x in range(10)]

OUT_DIR = config['out_dir']
SCRATCH_DIR = config['scratch_dir']

BED_FILE = config['bed_file']
REF = config['ref_fasta']
GNOMAD_AF = config['gnomad_af']
UCSC_RPMSK = config['ucsc_rpmsk']


ANNOVAR = config["annovar"]
ANNOVAR_DB = config["annovar_db"]

REPEAT_MASKER = config["repeat_masker"]
SEGDUP = config["segdup"]

HOMOPOLYMER_SCRIPT = config["homopolymer_script"]
CI_SCRIPT = config["ci_script"]
SUMMERIZE_SCRIPT = config["summerize_script"]

HEADER = ["#ID", "CHROM", "POS", "REF", "ALT", "ANNO", "GENE", "GNOMAD_FREQ", \
          "REPEAT_MASKER", "SEGDUP", "HOMOPOLYMER", "REF_SEQ", "DINUCLEOTIDE", \
          "NEAR_INDEL", "UCSC_RPMSK", "REF_COUNT", "ALT_COUNT", "MAF", "LOWER_CI",\
          "UPPER_CI", "CI_IS_GREATER", "NORMAL_REF_COUNT", "NORMAL_ALT_COUNT", \
          "NORMAL_MAF", "NORMAL_LOWER_CI", "NORMAL_UPPER_CI", "NORMAL_CI_IS_GREATER", \
          "TUMOR_IS_BLOOD", "TUMOR_IS_SPERM"]



import pandas as pd
import numpy as np
import sys, os


def make_input_dicts():
    f = open(config['input_files'], "r")

    tumor_dict = {}
    normal_dict = {}
    somatic_dict = {}
    germline_dict = {}

    for line in f:
        if line.startswith("#"):
            continue
        words = line.rstrip().split("\t")
        print(words)
        sample_id = words[0]
        tumor_id = words[1]
        normal_id = words[2]
        tumor_path = words[3]
        normal_path = words[4]
        somatic_vcf_path = words[5]
        germline_vcf_path = words[6]
      
        tumor_dict[sample_id] = [tumor_id, tumor_path]
        normal_dict[sample_id] = [normal_id, normal_path]
        germline_dict[sample_id] = germline_vcf_path
        somatic_dict[sample_id] = somatic_vcf_path
    f.close()
    return tumor_dict, normal_dict, somatic_dict, germline_dict


TUMOR_DICT, NORMAL_DICT, SOMATIC_DICT, GERMLINE_DICT = make_input_dicts()




rule all:
    input:
        OUT_DIR + "/final_summary.vcf",
              


#generate 1-based avinput
rule generate_avinput:
    input:
        vcf = lambda wildcards: SOMATIC_DICT[wildcards.sample]
    output:
        avinput = OUT_DIR + "/avintput/{sample}.avinput",
    shell:
        """ zcat {input.vcf} | grep -v "##" | grep "PASS" |  """
        """ awk -v OFS="\\t" "\$5!~/,/ {{print \$1, \$2, \$2+length(\$4)-1, \$4, \$5}}"  """
        """ >> {output.avinput} """


#generate 0-based bed file
rule generate_bed:
    input:
        vcf = lambda wildcards: SOMATIC_DICT[wildcards.sample]
    output:
        bed = OUT_DIR + "/bed/{sample}.bed",
    shell:
        """ zcat {input.vcf} | grep -v "##" | grep "PASS" |  """
        """ awk -v OFS="\\t" "\$5!~/,/ {{print \$1, \$2-1, \$2+length(\$4)-2, \$4, \$5}}"  """
        """ >> {output.bed} """



#split avinput to smaller files
rule split_avinput:
    input:
        avinput = OUT_DIR + "/avintput/{sample}.avinput",
    output:
        expand(SCRATCH_DIR + "/split_avinput/{{sample}}/{split}", split = SPLITS)
    params:
        outdir = SCRATCH_DIR + "/split_avinput/{sample}/"
    shell:
        """ split -d -l $(wc -l {input}|awk "{{print int((\$1+10-1)/10)}}") {input} {params.outdir} """


#use Renee's package to process these entries
rule check_homopolymer_dinucleotide_nearindel_rpmsk:
    input:
        avinput = SCRATCH_DIR + "/split_avinput/{sample}/{split}",
        germline_vcf = lambda wildcards: GERMLINE_DICT[wildcards.sample],
    output:
        outfile = SCRATCH_DIR + "/split_annotation/{sample}/{split}.homopolymer_dinucleotide_nearindel_rpmsk"
    params:
        cluster = "-q home -l nodes=1:ppn=4,mem=12gb -l walltime=24:00:00"
    shell:
        "python {HOMOPOLYMER_SCRIPT}"
        "    {input.avinput}"
        "    {input.germline_vcf}"
        "    {UCSC_RPMSK}"
        "    {output.outfile}"


#compute ci for this sample
rule compute_tumor_MAF_and_CI:
    input:
        tumor_bam = lambda wildcards: TUMOR_DICT[wildcards.sample][1],
        avinput = SCRATCH_DIR + "/split_avinput/{sample}/{split}",
    output:
        outfile = SCRATCH_DIR + "/split_annotation/{sample}/{split}.tumor_maf_ci",
    params:
        outdir = SCRATCH_DIR + "/split_annotation/{sample}/{split}_tumor_samtools_output/",
        cluster = "-q home -l walltime=24:00:00",
    shell:
        "python {CI_SCRIPT}"
        "    {input.tumor_bam}"
        "    {input.avinput}"
        "    {params.outdir}"
        "    {output.outfile}"



#compute ci for the corresponding normal sample
rule compute_normal_MAF_and_CI:
    input:
        normal_bam = lambda wildcards: NORMAL_DICT[wildcards.sample][1],
        avinput = SCRATCH_DIR + "/split_avinput/{sample}/{split}",
    output:
        outfile = SCRATCH_DIR + "/split_annotation/{sample}/{split}.normal_maf_ci",
    params:
        outdir = SCRATCH_DIR + "/split_annotation/{sample}/{split}_normal_samtools_output/",
        cluster = "-q home -l walltime=24:00:00",
    shell:
        "python {CI_SCRIPT}"
        "    {input.normal_bam}"
        "    {input.avinput}"
        "    {params.outdir}"
        "    {output.outfile}"


#gather results for homopolymer, dinucleotide, near_indeal, and rpmsk together
rule gather_homopolyer_results:
    input:
        expand(SCRATCH_DIR + "/split_annotation/{{sample}}/{split}.homopolymer_dinucleotide_nearindel_rpmsk", split=SPLITS)
    output:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}.homopolymer_dinucleotide_nearindel_rpmsk",
    params:
        cluster = "-q home -l walltime=1:00:00"
    run:
        print(output.outfile)
        wfile = open(output.outfile, "w")
        for file in input:
            print(file)
            with open(file, "r") as f:
                for line in f:
                    wfile.write(line)
        wfile.close()


#gather ci results for tumor sample
rule gather_tumor_ci_results:
    input:
        expand(SCRATCH_DIR + "/split_annotation/{{sample}}/{split}.tumor_maf_ci", split=SPLITS)
    output:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}.tumor_maf_ci",
    params:
        cluster = "-q home -l walltime=1:00:00"
    run:
        wfile = open(output.outfile, "w")
        for file in input:
            print(file)
            with open(file, "r") as f:
                for line in f:
                    if line.startswith("#"):
                        continue
                    wfile.write(line)
        wfile.close()

#gather ci results for normal sample
rule gather_normal_ci_results:
    input:
        expand(SCRATCH_DIR + "/split_annotation/{{sample}}/{split}.normal_maf_ci", split=SPLITS)
    output:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}.normal_maf_ci",
    params:
        cluster = "-q home -l walltime=1:00:00"
    run:
        wfile = open(output.outfile, "w")
        for file in input:
            print(file)
            with open(file, "r") as f:
                for line in f:
                    if line.startswith("#"):
                        continue
                    wfile.write(line)
        wfile.close()

#get annovar annotation
rule annovar_geneanno:
    input:
        avinput = OUT_DIR + "/avintput/{sample}.avinput",
    output:
        vcf = OUT_DIR + "/annotation/{sample}/{sample}.variant_function",
        exonic_vf = OUT_DIR + "/annotation/{sample}/{sample}.exonic_variant_function",
    params:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}",
        cluster = "-q home -l walltime=1:00:00"
    shell:
        "{ANNOVAR} -geneanno"
        "    -build hg19"
        "    -dbtype refGene"
        "    {input.avinput}"
        "    {ANNOVAR_DB}"
        "    -outfile {params.outfile}"

#get gnomad annotation
rule annovar_gnomad:
    input:
        avinput = OUT_DIR + "/avintput/{sample}.avinput",
    output:
        dropped = OUT_DIR + "/annotation/{sample}/{sample}.hg19_gnomad_genome_dropped",
        filtered = OUT_DIR + "/annotation/{sample}/{sample}.hg19_gnomad_genome_filtered",
    params:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}",
        cluster = "-q home -l walltime=1:00:00",
    shell:
        "{ANNOVAR} -filter"
        "    -build hg19"
        "    -dbtype gnomad_genome"
        "    {input.avinput}"
        "    {ANNOVAR_DB}"
        "    -outfile {params.outfile}"


rule check_repeats:
    input:
        bed = OUT_DIR + "/bed/{sample}.bed",
    output:
        outfile = OUT_DIR + "/annotation/{sample}/{sample}.repeats_annotation",
    params:
        cluster = "-q home -l walltime=1:00:00"
    shell:
        "module load bedtools;"
        "bedtools annotate"
        "    -i {input.bed}"
        "    -files {REPEAT_MASKER} {SEGDUP}"
        ">>{output.outfile};"


rule summarize_result:
    input:
        exon_vf = OUT_DIR + "/annotation/{sample}/{sample}.exonic_variant_function",
        vf = OUT_DIR + "/annotation/{sample}/{sample}.variant_function",
        gnomad_dropped = OUT_DIR + "/annotation/{sample}/{sample}.hg19_gnomad_genome_dropped",
        repeats = OUT_DIR + "/annotation/{sample}/{sample}.repeats_annotation",
        homopolymer = OUT_DIR + "/annotation/{sample}/{sample}.homopolymer_dinucleotide_nearindel_rpmsk",
        tumor_ci = OUT_DIR + "/annotation/{sample}/{sample}.tumor_maf_ci",
        normal_ci = OUT_DIR + "/annotation/{sample}/{sample}.normal_maf_ci"
    output:
        outfile = OUT_DIR + "/results/{sample}.vcf"
    params:
        tumor_id = lambda wildcards: TUMOR_DICT[wildcards.sample][0],
        cluster = "-q home -l walltime=1:00:00"
    shell:
        "python {SUMMERIZE_SCRIPT}"
        "       {params.tumor_id}"
        "       {input.exon_vf}"
        "       {input.vf}"
        "       {input.gnomad_dropped}"
        "       {input.repeats}"
        "       {input.homopolymer}"
        "       {input.tumor_ci}"
        "       {input.normal_ci}"
        "       {output.outfile}"


rule merge_results:
    input:
        expand(OUT_DIR + "/results/{sample}.vcf", sample=TUMOR_DICT.keys())
    output:
        outfile = OUT_DIR + "/final_summary.vcf",
    params:
        cluster = "-q home -l walltime=1:00:00"
    run:
        wfile = open(output.outfile, "w")
        wfile.write("\t".join(HEADER) + "\n")
        for file in input:
            print(file)
            with open(file, "r") as f:
                for line in f:
                    if line.startswith("#"):
                        continue
                    wfile.write(line)
        wfile.close()



